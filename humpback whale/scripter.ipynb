{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\n\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, Flatten, Input, Conv2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.optimizers import Adam, Adadelta\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.utils import to_categorical\n# from keras.applications.nasnet import NASNetLarge\nfrom keras.backend import sparse_categorical_crossentropy\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\nimport os\nfrom os import path, listdir\nimport gc\n\nimport cv2\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f89ec578d0346c1cfb23f9d184e35d96e257f2f0"
      },
      "cell_type": "code",
      "source": "listdir('../input')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cac2a94005b16b41c021e3dbd22bc52e12e0adcc"
      },
      "cell_type": "code",
      "source": "train_dset = pd.read_csv('../input/train.csv')\ntrain_image_path = '../input/train'\ntest_image_path = '../input/test'\n\ntest_csv = pd.read_csv('../input/sample_submission.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b05f10829fea6457c96b3b34aafec8b1508ab75f"
      },
      "cell_type": "code",
      "source": "train_dset.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba19d42a52e894f2597cd0a4a1b52f6a0d06f9b2"
      },
      "cell_type": "code",
      "source": "train_dset.Id.value_counts().head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "472bfe8d989a945ff66c4cf434469a112383d4d2"
      },
      "cell_type": "code",
      "source": "train_dset = train_dset[train_dset['Id'] != 'new_whale']\ntrain_dset.Id.value_counts().head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_y = train_dset['Id'].values\nlabels = pd.unique(train_y)\ntrain_y = pd.Series(train_y)\ntrain_y, _ = pd.factorize(train_y)\n\nidx_to_label = dict(zip(np.unique(train_y),labels))\n\n# data_gen = ImageDataGenerator(\n#         featurewise_center=False,\n#         samplewise_center=False,\n#         featurewise_std_normalization=False,\n#         samplewise_std_normalization=False,\n#         zca_whitening=False,\n#         rotation_range=10,\n#         zoom_range = 0.1,\n#         width_shift_range=0.1,\n#         height_shift_range=0.1,\n#         horizontal_flip=False,\n#         vertical_flip=False\n# )\n\nimg_dim = (128, 128)\nnum_channels = 1\nnum_classes = len(np.unique(train_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eb91450187daf932d8dd3c53b8f70eedd73539c6"
      },
      "cell_type": "code",
      "source": "train_x = []\ntest_x  = []\ntrain_imgs = train_dset['Image'].values\n\nfor img in train_imgs:\n    image = cv2.imread(path.join(train_image_path, img),0)\n    image = cv2.resize(image, img_dim)\n    image = np.array(image)\n    train_x.append(image)\n\ntrain_x = np.array(train_x)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dce2850ff6939e6eae1f1d13d77e28b74e3ce556"
      },
      "cell_type": "code",
      "source": "print(train_x.shape)\ntrain_x = np.reshape(train_x, (*train_x.shape,1))\nprint(train_x.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6a3271ba2045b8bfce3f7385d5d82a927694425d"
      },
      "cell_type": "code",
      "source": "print(type(train_y))\ntrain_y = np.reshape(train_y, (train_y.shape[0],))\nprint(np.shape(train_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "39ee6430ab58d378900d3d9bb0248b4d5b589964"
      },
      "cell_type": "code",
      "source": "# base_model = NASNetLarge(\n#                     input_shape=(*img_dim, num_channels,),\n#                     include_top=False,\n#                     weights='imagenet',\n#                     input_tensor=None,\n#                     pooling=None,\n#                 )\n\n# for layer in base_model.layers:\n#     layer.trainable = False\n\n\n# x = base_model.output\ninputs = Input(shape=(*img_dim,num_channels))\nx = Conv2D(filters=32, kernel_size=3, activation='relu')(inputs)\nx = BatchNormalization()(x)\nx = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D()(x)\nx = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Conv2D(filters=1, kernel_size=1, activation='relu')(x)\nx = GlobalMaxPooling2D()(x)\n# x = Flatten()(x)\nx = Dense(128, activation='tanh')(x)\nx = Dropout(0.3)(x)\nx = Dense(num_classes, activation='softmax')(x)\n\nmodel = Model(inputs=inputs, outputs=x)\n\nmodel.summary()\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=1e-3))\n\n# data_gen.fit(train_x)\n\nreduceLR = ReduceLROnPlateau(\n                            monitor='val_acc', \n                            patience=2, \n                            verbose=1, \n                            factor=0.2, \n                            min_lr=0.00001\n                        )\n\nearlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=0, mode='auto', baseline=None)\n\n# tensorboard = TensorBoard(log_dir='./logs', write_images=True, batch_size=128, write_graph=True, write_grads=True)\n\n# checkpoint = ModelCheckpoint('./checkpoints/', monitor='val_loss', save_best_only=True)\n\n# model.fit_generator(\n# \t\t\t\t\tdata_gen.flow(train_x, train_y, batch_size=128),\n# \t\t\t\t\tshuffle=True, \n# \t\t\t\t\tepochs=15,\n# \t\t\t\t\tcallbacks=[earlystop, tensorboard, reduceLR, checkpoint]\n# \t\t\t\t)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c231dbd47c0cda49ed3e63aaeecf1f207cb4b119",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "model.fit(train_x, train_y, batch_size=5, epochs=25, callbacks=[earlystop, reduceLR])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "20191645cf652850b2740500479a9a17d77b3aa3"
      },
      "cell_type": "code",
      "source": "del train_x, train_y, train_dset\nimport gc\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f926c21e46d0a85468580aec08d1a2632464e28"
      },
      "cell_type": "code",
      "source": "for img in listdir(test_image_path):\n    image = cv2.imread(path.join(test_image_path, img), 0)\n    image = cv2.resize(image, img_dim)\n    image = np.array(image)\n    test_x.append(image)\n    \ntest_x = np.array(test_x)\nprint(test_x.shape)\ntest_x = np.reshape(test_x, (*test_x.shape,1))\nprint(test_x.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f67b9047c132d03e8b690e30ef06d9949e8f7c19"
      },
      "cell_type": "code",
      "source": "def topK(predictions, k = 5):\n    predictions = [np.absolute(np.argsort(-1*x))[:k] for x in predictions]\n    predictions = [idx_to_label[i] for prediction in predictions for i in prediction]\n    return predictions\n\npreds = model.predict(test_x)\nprediction = topK(preds, 5)\n\nprint(preds[1])\nprint(prediction[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a66b3e5ad976d81c6fb7dd82c340247a3b968fec"
      },
      "cell_type": "code",
      "source": "predictions = pd.DataFrame(data=test_csv)\npredictions.drop(columns=['Id'], inplace=True)\npredictions['Id'] = [\" \".join(predicted) for preds in prediction]\npredictions.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}